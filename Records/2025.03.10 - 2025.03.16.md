## 本周任务
1. 在spider1.0和Bird数据集上测试llm的text-to-sql生成效果，并统计语义错误（即可执行但执行结果与标准答案不符）。下面是实验设置和实验记录：
	* text-to-sql datasets
		* Spider1.0：[Spider1.0_数据集说明](../Spider1.0/Spider1.0_数据集说明.md)
		* BIRD : [BIRD_数据集说明](../BIRD/BIRD_数据集说明.md)
		* ~~Spider2.0 :  https://spider2-sql.github.io/ ~~
	* llm
		* GPT-3.5-Turbo、~~智谱大模型、 Deepseek，CodeLlama~~
	* experiment records 
		* [实验记录_在Spider1.0上简单测试LLM的text-to-sql能力2.0](../Spider1.0/实验记录_在Spider1.0上简单测试LLM的text-to-sql能力2.0.md)
		* [实验记录_在BIRD上简单测试LLM的text-to-sql能力2.0](../BIRD/实验记录_在BIRD上简单测试LLM的text-to-sql能力2.0.md)
2. 分析spider1.0上text-to-sql实验结果的logic出错的分类和原因
	* [标记记录_分析Spider1.0上text-to-sql任务的逻辑错误_n选m分类器](标记记录_分析Spider1.0上text-to-sql任务的逻辑错误_n选m分类器.md)
	* 分析error type和root cause，表象可能是用错某个函数，根本原因是LLM对某个操作理解不当
	* gpt-3.5-turbo_3.0：spider-train-merged-info https://docs.qq.com/sheet/DTG9La1VpbXd6TFhT?tab=000001
	* gpt-3.5-turbo_2.0：spider-test-merged-info https://docs.qq.com/sheet/DTENnVHBZbHZDcHJ3?tab=000001
3. 论文阅读
	* From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?  （3.27分享，ICSE25）
	* LLM Hallucinations in Practical Code Generation:Phenomena, Mechanism, and itigation

