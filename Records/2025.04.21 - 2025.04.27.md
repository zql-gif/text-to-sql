## 本周任务
1. 在spider1.0和Bird数据集上测试llm的text-to-sql生成效果，并统计语义错误（即可执行但执行结果与标准答案不符）。下面是实验设置和实验记录：
	* text-to-sql datasets
		* Spider1.0：[Spider1.0_数据集说明](../Spider1.0/Spider1.0_数据集说明.md)
		* BIRD : [BIRD_数据集说明](../BIRD/BIRD_数据集说明.md)
		* ~~Spider2.0 :  https://spider2-sql.github.io/ ~~
	* llm
		* GPT-3.5-Turbo、~~智谱大模型、 Deepseek，CodeLlama~~
	* experiment records 
		* [实验记录_在Spider1.0上简单测试LLM的text-to-sql能力2.0](../Spider1.0/实验记录_在Spider1.0上简单测试LLM的text-to-sql能力2.0.md)
		* [实验记录_在BIRD上简单测试LLM的text-to-sql能力2.0](../BIRD/实验记录_在BIRD上简单测试LLM的text-to-sql能力2.0.md)
2. 分析spider1.0上text-to-sql实验结果的logic出错的分类和原因
	* 分析并人工标记部分error type和root cause，表象可能是用错某个函数，根本原因是LLM对某个操作理解不当。
	* 概括总结若干类logic error type，包括类型名称，类型定义。
	* 微调llm进行自动化标记
		* [标记记录_分析Spider1.0上text-to-sql任务的逻辑错误_n选m分类器](标记记录_分析Spider1.0上text-to-sql任务的逻辑错误_n选m分类器.md)
		* [[标记记录_分析Spider1.0上text-to-sql任务的逻辑错误_二分分类器]]
