自动化程序细化：使用细化演算引导和验证代码大语言模型

# 0 Abstract
* 代码驱动的大语言模型（LLMs），如Copilot可以轻松生成代码
	- LLM 所生成的代码不具备正确性保障，“幻觉”问题。
	- 从规范到代码的端到端过程是一个不透明、不可控的“黑盒”，用户难以理解并信任生成的代码。

- 程序细化（Program Refinement）：将高级规范语句转换为可执行代码，同时保持其正确性。
- 传统程序细化工具主要面向形式化方法专家，**缺乏自动化能力和可扩展性**。

- Refine4LLM：将程序细化引入 LLM 的代码生成过程，旨在指导 LLM 并验证其生成的代码，同时将程序细化转化为一个更易用、灵活的框架。旨在实现以下目标：
	- 形式化地细化规范；
	- 自动化地使用细化演算对 LLM 进行提示和引导；
	- 与 LLM 交互生成代码；
	- 验证生成的代码是否满足约束条件，从而确保其正确性；
	- 学习并构建更高级的细化定律，以扩展细化演算体系。

# 1 Introduction

## 1.1 Challenges in LLM-based Code Generation
* Challenges
	* “幻觉”问题：LLM 所生成的代码不具备正确性保障，数学证明表明幻觉不可避免[60]
	* 从规范到代码的端到端过程是一个不透明、不可控的“黑盒”：用户难以理解并信任生成的代码。
*  Classic refinement example - square root algorithm
	* specification：Find the square root of N within the error bound e.
	* 正确思路：通常使用 **二分法** 或 **牛顿迭代法** 等数值逼近算法：设定一个误差界 `e`；不断逼近，使得 `abs(x² - N) < e`
	* GitHub Copilot 和 OpenAI GPT-4 所生成的代码会陷入无限循环， OpenAI 的 o1-preview 模型在某些情况下则给出了错误的结果。
	* Copilot：**生成的程序在输入 n < 1 时是错误的，会陷入死循环。** 当 `n < 1` 时，`high = n < 1`，而实际上 `sqrt(n)` 可能远大于 `n`。例如，`sqrt(0.1) ≈ 0.316`，但 `high = 0.1`，明显不足，**目标值不在搜索区间内**。循环无法终止。 从数学上讲，变量 `high` 作为N 的平方根的上界，其选择应大于 N+1/4，因为对于所有 N > 0，都有 (N+1/4)^2≥N。
	* GPT-4： 生成的代码在某些情况（如求 sqrt(5)）下会失败，因为变量 `x` 会趋近于某个固定点但由于浮点精度误差无法终止循环。 终止条件`while x*x > N`有错误。当 `x` 接近但不等于 `sqrt(N)` 时，程序在浮点精度无法再前进时仍然继续迭代，永远不会结束。修正建议是加入合适的误差终止条件：`while abs(x * x - N) > e`
	* OpenAI o1-preview ：模型生成的代码在 (e/4)^2 时有时会给出错误结果，因为变量 `x` 被初始化为负数。- 初始化 `x = math.sqrt(N) - e/2.0`  ，当 `N` 很小时（远小于 `e`），`math.sqrt(N)` 本身接近 0，减去 `e/2.0` 就可能为负数。修正建议是将初值约束在合法非负区间：`x = max(0, math.sqrt(N) - e/2.0)`。

![[Pasted image 20250422145025.png]]

* Current strategies：输入引导和输出验证
	* 输入引导： 通过向其提供与任务相关的信息来引导其朝着更简洁、在其能力范围内的解法前进。通常采用非正式的启发式方法，例如CoT [59]。研究 [60] 在数学上证明，多个 LLM 的集成本质上仍然是一个 LLM，无法根本解决幻觉问题。
	* 输出验证：最新的 LLM 验证方法依赖多个 LLM，通过多数投票或自然语言中的共识来评估输出 [1, 40, 64]。

* Refine4LLM ：融合了 LLM 与符号人工智能系统 CoqHammer [20]，通过程序细化与验证来在约束条件下引导 LLM，并验证其生成代码的正确性。

## 1.2 Challenges in Traditional Program Refinement
* 程序精化：一个**不可执行的规范**来描述程序应具备的行为，然后通过一系列**保持正确性的变换步骤**，将其转化为一个可执行程序。
* 程序精化演算（refinement calculus）[5, 14, 41, 52, 56] ：对**逐步精化式程序构造方法**的一种形式化表达。
	* 转化过程**主要依赖人工进行**，既耗时又容易出错。
	* 手动编写代码的需求使得程序精化过程**劳动强度大，难以自动化**。
* 将**大语言模型（LLMs）在代码生成方面的能力**引入精化流程，是一种**合理的发展方向**。
* **Refine4LLM**：第一个将**形式化的程序精化演算**与**非形式的大语言模型**相结合，支持从规范出发，逐步生成经过验证的代码。
	- 提出一个名为 **Refine4LLM** 的框架，用于实现由大语言模型辅助的自动化程序精化。该框架包括一个**形式化规范语言** Lspec、一个与我们精化演算相关联的**编程语言** Lpl，以及一套用于**验证生成代码**的验证策略。
	- 提出一种**精化定律学习策略**，用于推导出更高级的精化规则，以此**减少程序精化过程的深度**。
	- 设计一种**自顶向下拆分与自底向上精化算法**，用于构建程序精化库，从而**降低规范的复杂度**。

## 1.3 Outline
- 第 2 节介绍了程序精化的背景知识。
- 第 3 节通过一个平方根算法的示例说明了研究动机。
- 第 4 节展示了工具 Refine4LLM 的整体概览
- 随后在第 5 节定义了形式化的规范语言和程序语言。
- Refine4LLM 采用了一种学习策略，用于构建新的精化定律，以减少精化过程的深度，这部分内容详见第 6 节。
- 第 7 节介绍了一个形式化系统，它可以基于精化定律自动地、形式化地对规范进行精化，并生成相应的证明义务。Refine4LLM 使用自动定理证明器（ATP）来验证精化定律的正确性。
- 第 8 节介绍了非形式系统，包括一个**自顶向下**的算法用于拆分高层规范，以及一个**自底向上**的算法结合大语言模型（LLMs）对子规范进行精化。
- 第 9 节展示了我们在经典程序精化基准任务 [37] 以及大语言模型基准集 Humaneval 和 EvalPlus 数据集 [38] 上对 Refine4LLM 的评估结果。